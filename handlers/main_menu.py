# main.py

import os
import logging
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
)
import openai
from dotenv import load_dotenv
from typing import List

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö –æ—Ç–æ—á–µ–Ω–Ω—è
load_dotenv()

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è OpenAI API
openai.api_key = os.getenv('OPENAI_API_KEY')

# –Ü–º–ø–æ—Ä—Ç —Ö–µ–Ω–¥–ª–µ—Ä—ñ–≤ —Ç–∞ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä
from handlers.start import start
from handlers.main_menu import (
    get_main_menu_keyboard,
    get_heroes_menu_keyboard,
    get_class_characters_keyboard
)
from data.characters import CHARACTERS
from data.classes import CLASSES

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
async def send_reply(update: Update, text: str, reply_markup=None) -> None:
    try:
        await update.message.reply_text(text, parse_mode='Markdown', reply_markup=reply_markup)
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤—ñ–¥–ø—Ä–∞–≤—Ü—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {e}")

# –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–µ—Ä—Å–æ–Ω–∞–∂—ñ–≤ –∑–∞ –∫–ª–∞—Å–æ–º
def get_characters_by_class(character_class: str) -> List[str]:
    return CHARACTERS.get(character_class, [])

# –û–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_input = update.message.text
    user_id = update.effective_user.id
    logger.info(f"–û—Ç—Ä–∏–º–∞–Ω–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—ñ–¥ {user_id}: {user_input}")

    # –ú–æ–∂–Ω–∞ –≤–∏–¥–∞–ª–∏—Ç–∏ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É –º–æ–≤–∏, —è–∫—â–æ –≤—Å—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
    try:
        lang = detect(user_input)
        logger.info(f"–í–∏–∑–Ω–∞—á–µ–Ω–∞ –º–æ–≤–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {lang}")
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏: {e}")
        await send_reply(update, "–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –º–æ–≤—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.")
        return

    # –û–±—Ä–æ–±–∫–∞ –≤–∏–±–æ—Ä—É –∑ –º–µ–Ω—é
    if user_input in ["üì∞ –ù–æ–≤–∏–Ω–∏", "üìö –ì–∞–π–¥–∏", "üîß –û–Ω–æ–≤–ª–µ–Ω–Ω—è", "üìò –ü–æ—Ä–∞–¥–∏ –¥–ª—è –Ω–æ–≤–∞—á–∫—ñ–≤", "üèÜ –¢—É—Ä–Ω—ñ—Ä–∏", "ü¶∏ –ì–µ—Ä–æ—ó", "‚ùì –î–æ–ø–æ–º–æ–≥–∞"]:
        await handle_menu_selection(update, user_input)
    elif user_input in CLASSES:
        await handle_hero_class_selection(update, context, user_input)
    elif user_input in get_characters_by_class(context.user_data.get('hero_class', '')):
        context.user_data['character'] = user_input
        await send_final_request(update, context)
    elif user_input == "–ù–∞–∑–∞–¥":
        await handle_back(update, context)
    else:
        await handle_gpt_query(update, user_input)

# –û–±—Ä–æ–±–∫–∞ –≤–∏–±–æ—Ä—É –∑ –≥–æ–ª–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é
async def handle_menu_selection(update: Update, user_input: str) -> None:
    if user_input == "ü¶∏ –ì–µ—Ä–æ—ó":
        reply_markup = get_heroes_menu_keyboard()
        await send_reply(update, "–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å –≥–µ—Ä–æ—è:", reply_markup=reply_markup)
    else:
        queries = {
            "üì∞ –ù–æ–≤–∏–Ω–∏": "–ù–∞–¥–∞–π—Ç–µ –æ—Å—Ç–∞–Ω–Ω—ñ –Ω–æ–≤–∏–Ω–∏ –ø—Ä–æ Mobile Legends –Ω–∞ –ª–∏—Å—Ç–æ–ø–∞–¥ 2024 —Ä–æ–∫—É.",
            "üìö –ì–∞–π–¥–∏": "–Ø–∫—ñ —î –∫–æ—Ä–∏—Å–Ω—ñ –≥–∞–π–¥–∏ –¥–ª—è –≥—Ä–∏ Mobile Legends –Ω–∞ –ª–∏—Å—Ç–æ–ø–∞–¥ 2024 —Ä–æ–∫—É?",
            "üîß –û–Ω–æ–≤–ª–µ–Ω–Ω—è": "–Ø–∫—ñ –æ—Å—Ç–∞–Ω–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –≤ Mobile Legends –Ω–∞ –ª–∏—Å—Ç–æ–ø–∞–¥ 2024 —Ä–æ–∫—É?",
            "üìò –ü–æ—Ä–∞–¥–∏ –¥–ª—è –Ω–æ–≤–∞—á–∫—ñ–≤": "–Ø–∫—ñ –ø–æ—Ä–∞–¥–∏ –≤–∏ –º–æ–∂–µ—Ç–µ –¥–∞—Ç–∏ –Ω–æ–≤–∞—á–∫–∞–º —É Mobile Legends?",
            "üèÜ –¢—É—Ä–Ω—ñ—Ä–∏": "–Ø–∫—ñ –Ω–∞–π–±–ª–∏–∂—á—ñ —Ç—É—Ä–Ω—ñ—Ä–∏ Mobile Legends?",
            "‚ùì –î–æ–ø–æ–º–æ–≥–∞": "–î–µ —è –º–æ–∂—É –∑–Ω–∞–π—Ç–∏ –¥–æ–ø–æ–º–æ–≥—É –ø–æ Mobile Legends?"
        }
        query = queries.get(user_input, "–ù–µ–≤—ñ–¥–æ–º–∞ –æ–ø—Ü—ñ—è.")
        await handle_gpt_query(update, query)

# –û–±—Ä–æ–±–∫–∞ –≤–∏–±–æ—Ä—É –∫–ª–∞—Å—É –≥–µ—Ä–æ—è
async def handle_hero_class_selection(update: Update, context: ContextTypes.DEFAULT_TYPE, hero_class: str) -> None:
    context.user_data['hero_class'] = hero_class
    characters = get_characters_by_class(hero_class)
    if characters:
        reply_markup = get_class_characters_keyboard(hero_class)
        await send_reply(update, f"–û–±–µ—Ä—ñ—Ç—å –≥–µ—Ä–æ—è –∫–ª–∞—Å—É {hero_class}:", reply_markup=reply_markup)
    else:
        await send_reply(update, f"–î–ª—è –∫–ª–∞—Å—É {hero_class} –Ω–µ–º–∞—î –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –≥–µ—Ä–æ—ó–≤.")

# –û–±—Ä–æ–±–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ù–∞–∑–∞–¥"
async def handle_back(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–æ–±–Ω–∏–∫ –∫–Ω–æ–ø–∫–∏ '–ù–∞–∑–∞–¥'
    """
    if 'character' in context.user_data:
        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ –≤–∏–±–æ—Ä—É –≥–µ—Ä–æ—è
        hero_class = context.user_data.get('hero_class')
        if hero_class:
            reply_markup = get_class_characters_keyboard(hero_class)
            await send_reply(update, f"–û–±–µ—Ä—ñ—Ç—å –≥–µ—Ä–æ—è –∫–ª–∞—Å—É {hero_class}:", reply_markup=reply_markup)
        else:
            await send_reply(update, "–û–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é –∑ –º–µ–Ω—é:", reply_markup=get_main_menu_keyboard())
    elif 'hero_class' in context.user_data:
        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ –º–µ–Ω—é –∫–ª–∞—Å—ñ–≤
        reply_markup = get_heroes_menu_keyboard()
        await send_reply(update, "–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å –≥–µ—Ä–æ—è:", reply_markup=reply_markup)
    else:
        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ –≥–æ–ª–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é
        await start(update, context)

# –û–±—Ä–æ–±–∫–∞ –∑–∞–ø–∏—Ç—É –¥–æ GPT-4
async def handle_gpt_query(update: Update, user_input: str) -> None:
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",  # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞–∑–≤–∞ –º–æ–¥–µ–ª—ñ
            messages=[{"role": "user", "content": user_input}],
            max_tokens=1000,
            temperature=0.7
        )
        reply_text = response['choices'][0]['message']['content']
        formatted_reply = f"*–í–∞—à –∑–∞–ø–∏—Ç:*\n{user_input}\n\n*–í—ñ–¥–ø–æ–≤—ñ–¥—å:*\n{reply_text}\n\n_–î–∂–µ—Ä–µ–ª–æ: GPT-4_"
        await send_reply(update, formatted_reply)
    except openai.error.RateLimitError:
        logger.warning("–õ—ñ–º—ñ—Ç –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ—Å—è–≥–Ω—É—Ç–æ. –ü–æ–≤—Ç–æ—Ä —Å–ø—Ä–æ–±–∏...")
        await send_reply(update, "–õ—ñ–º—ñ—Ç –∑–∞–ø–∏—Ç—ñ–≤ –ø–µ—Ä–µ–≤–∏—â–µ–Ω–æ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –¥–µ–∫—ñ–ª—å–∫–∞ —Ö–≤–∏–ª–∏–Ω.")
    except openai.error.OpenAIError as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ GPT-4: {e}")
        await send_reply(update, "–°—Ç–∞–ª–∞—Å—å —Ç–µ—Ö–Ω—ñ—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
    except Exception as e:
        logger.error(f"–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        await send_reply(update, "–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.")

# –ù–∞–¥—Å–∏–ª–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≥–µ—Ä–æ—è
async def send_final_request(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    hero_class = context.user_data.get('hero_class')
    character = context.user_data.get('character')

    if hero_class and character:
        hero_info_request = (
            f"–ù–∞–¥–∞–π—Ç–µ –¥–µ—Ç–∞–ª—å–Ω–∏–π –æ–ø–∏—Å —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—é —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≥–µ—Ä–æ—è {character} "
            f"–∑ –∫–ª–∞—Å—É {hero_class} —É –≥—Ä—ñ Mobile Legends –Ω–∞ –ª–∏—Å—Ç–æ–ø–∞–¥ 2024 —Ä–æ–∫—É."
        )
        logger.info(f"–ó–∞–ø–∏—Ç –Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≥–µ—Ä–æ—è {character} ({hero_class})")

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": hero_info_request}],
                max_tokens=1000,
                temperature=0.7
            )
            reply_text = response['choices'][0]['message']['content']
            formatted_reply = f"*–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –≥–µ—Ä–æ—è {character}:*\n{reply_text}\n\n_–î–∂–µ—Ä–µ–ª–æ: GPT-4_"
            await send_reply(update, formatted_reply)
        except openai.error.OpenAIError as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –ø—Ä–æ –≥–µ—Ä–æ—è: {e}")
            await send_reply(update, "–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≥–µ—Ä–æ—è. –û—Å—å –∑–∞–≥–∞–ª—å–Ω–∏–π –æ–ø–∏—Å.")
            general_description_request = f"–ù–∞–¥–∞–π—Ç–µ –∑–∞–≥–∞–ª—å–Ω–∏–π –æ–ø–∏—Å –≥–µ—Ä–æ—è {character}."
            await handle_gpt_query(update, general_description_request)
        except Exception as e:
            logger.error(f"–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –ø—Ä–æ –≥–µ—Ä–æ—è: {e}")
            await send_reply(update, "–°—Ç–∞–ª–∞—Å—å –ø–æ–º–∏–ª–∫–∞. –ë—É–¥—å –ª–∞—Å–∫–∞, —Å–ø—Ä–æ–±—É–π—Ç–µ –∑–Ω–æ–≤—É.")

        # –û—á–∏—â–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        context.user_data.clear()
    else:
        await send_reply(update, "–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å –≥–µ—Ä–æ—è –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó.")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Telegram-–±–æ—Ç–∞
def main() -> None:
    token = os.getenv('TELEGRAM_TOKEN')
    if not token:
        logger.error("TELEGRAM_TOKEN –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —É –∑–º—ñ–Ω–Ω–∏—Ö –æ—Ç–æ—á–µ–Ω–Ω—è.")
        return

    app = ApplicationBuilder().token(token).build()

    # –†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è —Ö–µ–Ω–¥–ª–µ—Ä—ñ–≤
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–∏–π —Ç–∞ –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–±–æ—Ç–∏")
    app.run_polling()

if __name__ == "__main__":
    main()
